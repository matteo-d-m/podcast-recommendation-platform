version: "3.8"

services:
  spark-master:
    image: ${SPARK_IMAGE_NAME}:${SPARK_IMAGE_TAG}
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"    # Spark master port
      - "8080:8080"    # Spark web UI
    networks:
      - kafka-net

  spark-worker-1:
    image: ${SPARK_IMAGE_NAME}:${SPARK_IMAGE_TAG}
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=${SPARK_URL}

    volumes:
      - ${PWD}/spark:/opt/spark_jobs
      - ${PWD}/scripts:/opt/scripts
      - ${PWD}/data:/data
    env_file:
      - ../../.env.development
    depends_on:
      - spark-master
    networks:
      - kafka-net

  spark-streaming:
    image: ${SPARK_IMAGE_NAME}:${SPARK_IMAGE_TAG}
    container_name: spark-streaming
    command: >
      spark-submit
      --master ${SPARK_URL}
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.6,io.delta:delta-spark_2.12:3.1.0
      --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
      --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
      --conf spark.sql.session.timeZone=UTC
      /opt/project/spark_jobs/pipelines/streaming_user_events_pipeline.py
    environment:
      - PYSPARK_PYTHON=python3
    env_file:
      - ../../.env.development
    volumes:
      - ${PWD}:/opt/project
      - ${PWD}/data:/data
    depends_on:
      - spark-master,
      - spark-worker-1
    networks:
      - kafka-net

networks:
  kafka-net:
    external: true
    name: kafka-net

