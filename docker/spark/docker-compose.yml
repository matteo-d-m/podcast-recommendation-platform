version: "3.8"

services:
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"    # Spark master port
      - "8080:8080"    # Spark web UI

  spark-worker-1:
    image: bitnami/spark:latest
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master

  spark-worker-2:
    image: bitnami/spark:latest
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
  
  spark-worker-3:
    image: bitnami/spark:latest
    container_name: spark-worker-3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master

  spark-streaming: #always-on container (streaming data)
    build:
      context: ../..
      dockerfile: docker/spark/Dockerfile 
    container_name: spark-streaming
    command: ["python", "main.py", "--job", "streaming"]
    environment:
      - PYSPARK_SUBMIT_ARGS=--master spark://spark-master:7077 pyspark-shell
    volumes:
      - ./data:/data
      - ./spark:/app
    working_dir: /app
    restart: always
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - spark-worker-3