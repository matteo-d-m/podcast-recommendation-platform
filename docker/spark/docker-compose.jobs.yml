#ONE SHOT CONTAINERS - batch processing and summary processing
x-spark-job-template: &spark-job-base #template,reusable block
  build:
    context: ../..
    dockerfile: docker/spark/Dockerfile 
  image: spark-job
  environment:
    - PYSPARK_SUBMIT_ARGS=--master spark://spark-master:7077 pyspark-shell
  volumes:
    - ./data:/data
    - ./spark:/app
  working_dir: /app

services:
  spark-job-metadata:
    <<: *spark-job-base
    command: ["python", "main.py", "--job", "metadata"]

  spark-job-transcripts-en:
    <<: *spark-job-base
    command: ["python", "main.py", "--job", "transcripts-en"]

  spark-job-transcripts-foreign:
    <<: *spark-job-base
    command: ["python", "main.py", "--job", "transcripts-foreign"]

  spark-job-summary:
    <<: *spark-job-base
    command: ["python", "main.py", "--job", "summary"]