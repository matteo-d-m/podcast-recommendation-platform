# ==============================================================================
# MongoDB (transcript similarities)
# ==============================================================================
MONGO_INITDB_ROOT_USERNAME=mongo
MONGO_INITDB_ROOT_PASSWORD=mongo

MONGO_URI=mongodb://mongo:mongo@localhost:27017
MONGO_DB=podcasts
MONGO_COLLECTION=similarities
EPISODE_ID_FIELD=new_episode_id

# MongoDB (ALS outputs / user events)
MONGO_DB_USER_EVENTS=recommendations_users
MONGO_COLLECTION_USER_EVENTS=training_user_events

# ==============================================================================
# Airflow 
# ==============================================================================
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB_AIRFLOW=airflow
AIRFLOW_ADMIN_USER_FIRSTNAME=Admin
AIRFLOW_ADMIN_USER_LASTNAME=User
AIRFLOW_ADMIN_USER_ROLE=Admin
AIRFLOW_ADMIN_USER_EMAIL=admin@example.com
AIRFLOW_IMAGE_NAME=my-custom-airflow-image
AIRFLOW_IMAGE_TAG=2.9.0
AIRFLOW__WEBSERVER__SECRET_KEY=4LbWqOsAR-Nrw19Vfsq8EoOL7NrA3zyohL7xC1ZrOZQ


# ==============================================================================
# Podcast Index API 
# ==============================================================================
API_PODCAST_INDEX_KEY=4YCF385ZNXLEHADRUSFV
API_PODCAST_INDEX_SECRET='YcjAfd9x7S$$qX^4u#n$rvLD$X6c^pT87ShWvF3V'

# ==============================================================================
# Kafka
# ==============================================================================
KAFKA_URL=kafka1:9092
KAFKA_SERVERS=kafka1:9092
TOPIC_EPISODE_METADATA=episode-metadata
TOPIC_USER_EVENTS_STREAMING=streaming-user-events
TOPIC_EPISODES_ID=episodes-id

# ==============================================================================
# Spark
# ==============================================================================
SPARK_URL=spark://spark-master:7077
SPARK_IMAGE_NAME=my-custom-spark-image
SPARK_IMAGE_TAG=3.5.6
DELTA_PKG=io.delta:delta-spark_2.12:3.2.0
MONGO_PKG=org.mongodb.spark:mongo-spark-connector_2.12:10.3.0

# ==============================================================================
# Delta paths (containers/shared volume)
# ==============================================================================
DELTA_PATH_EPISODES=/data/delta/episodes
DELTA_PATH_TRANSCRIPTS=/data/delta/transcripts
DELTA_PATH_VECTORS=/data/delta/vectors
DELTA_PATH_SIMILARITIES=/data/delta/similarities

# Delta user-events (daily aggregates)
DELTA_PATH_DAILY=/data/delta/user_vs_episode_daily

# Model artifact output (Spark ML write().save)
ALS_MODEL_PATH=/data/models/als_model

# Streaming checkpoint directory (must persist across restarts)
USER_EVENT_STREAM=/data/streaming/user-events

# ==============================================================================
# Demo / local utilities (not read by settings.py unless wired)
# ==============================================================================
SAMPLE_EPISODES_JSON_PATH=/data/transcripts_demo

# ==============================================================================
# Transcripts: Model + Embeddings
# ==============================================================================
MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
MAX_TOKENS=512
OVERLAP=32
SAFETY_MARGIN=8
BATCH_SIZE=64
DEVICE=cpu
TOP_K=3

# ==============================================================================
# Control flags - transcript similarities
# ==============================================================================
RECOMPUTE_ALL=false
WITHIN_BATCH_IF_EMPTY=true
BATCH_DATE=""

# ==============================================================================
# User Event Simulation
# ==============================================================================
NUM_USERS=50
MIN_EPS_PER_USER=1
MAX_EPS_PER_USER=5
EPISODE_LIMIT=500
EPISODE_SAMPLE_N=300
